---
phase: 09-performance-frontend-tests
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/app/main.py
  - backend/app/middleware/query_logging.py
  - backend/app/routers/reports.py
autonomous: true
requirements: [PERF-01, PERF-02, PERF-03]

must_haves:
  truths:
    - "Dashboard widget API calls execute in parallel when page loads"
    - "Navigating away and back to dashboard reuses cached data without refetch"
    - "Backend logs show all SQL queries with execution time for report endpoints"
    - "No N+1 query patterns exist in report endpoints"
  artifacts:
    - path: "backend/app/middleware/query_logging.py"
      provides: "SQLAlchemy query logging middleware"
      min_lines: 30
    - path: "backend/app/main.py"
      provides: "Query logging middleware registration"
      contains: "query_logging"
  key_links:
    - from: "frontend/src/components/widgets/LazyWidgets.tsx"
      to: "frontend/src/hooks/useWidgetData.ts"
      via: "SWR hooks with dashboardId cache keys"
      pattern: "useSWR.*dashboardId"
    - from: "backend/app/routers/reports.py"
      to: "backend/app/middleware/query_logging.py"
      via: "Middleware logs all DB queries"
      pattern: "before_cursor_execute"
---

<objective>
Verify parallel widget fetching, confirm SWR caching behavior, and add backend query logging to detect N+1 patterns.

Purpose: Validate that Phase 7-8 work already satisfies PERF-01/02, add observability for PERF-03.
Output: Query logging middleware, performance verification documentation.
</objective>

<execution_context>
@/Users/joe/.claude/agents/gsd-executor.md
@/Users/joe/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-dashboard-polish-error-handling/08-01-SUMMARY.md
@.planning/phases/08-dashboard-polish-error-handling/08-03-SUMMARY.md
@frontend/src/hooks/useWidgetData.ts
@frontend/src/components/widgets/LazyWidgets.tsx
@backend/app/routers/reports.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add SQLAlchemy query logging middleware</name>
  <files>
    backend/app/middleware/query_logging.py
    backend/app/main.py
  </files>
  <action>
Create `backend/app/middleware/query_logging.py` with SQLAlchemy event listener:
- Listen to `before_cursor_execute` event to log all SQL queries
- Include query text, execution time, and request context
- Use Python logging module (level: DEBUG for queries, INFO for slow queries >500ms)
- Make it conditional on `ENABLE_QUERY_LOGGING` env var (default: False)

Register middleware in `backend/app/main.py`:
- Import query logging module
- Initialize on startup if env var enabled
- Add comment explaining usage for N+1 detection

Pattern reference from SQLAlchemy docs: https://docs.sqlalchemy.org/en/20/core/events.html#sqlalchemy.events.ConnectionEvents.before_cursor_execute

Do NOT enable by default in production — use for development N+1 analysis only.
  </action>
  <verify>
    Run `make backend` with `ENABLE_QUERY_LOGGING=1`, visit dashboard, check logs for SQL query output
  </verify>
  <done>
    Query logging middleware exists, logs SQL with timing, disabled by default
  </done>
</task>

<task type="auto">
  <name>Task 2: Verify parallel widget fetching and SWR caching</name>
  <files>
    .planning/phases/09-performance-frontend-tests/09-01-VERIFICATION.md
  </files>
  <action>
Create verification document with:

1. **Parallel Fetching Test (PERF-01):**
   - Open browser DevTools Network tab
   - Navigate to dashboard page
   - Verify all 9 widget API calls (`/api/v1/reports/*`) initiate within ~100ms window
   - Document: screenshot or HAR export showing parallel requests
   - Result: PASS if requests overlap in timing, FAIL if sequential

2. **SWR Cache Test (PERF-02):**
   - Visit dashboard page (cache miss — see 9 requests)
   - Navigate to transactions page
   - Navigate back to dashboard
   - Verify: NO new network requests to `/api/v1/reports/*` (cache hit)
   - Change dashboard tab → verify new requests with different dashboardId
   - Document: before/after request counts
   - Result: PASS if navigation reuses cache, new dashboard fetches fresh

3. **N+1 Query Check (PERF-03):**
   - Enable query logging: `ENABLE_QUERY_LOGGING=1 make backend`
   - Trigger each report endpoint via curl or browser
   - Check logs for repeated queries with same pattern but different IDs
   - Common N+1 pattern: `SELECT * FROM tags WHERE id = ?` repeated 100 times
   - Document: any N+1 patterns found + which endpoints
   - Result: PASS if no N+1 patterns, FAIL with remediation plan

Include commands to reproduce each test.
  </action>
  <verify>
    Verification document exists with PASS/FAIL results for all 3 tests
  </verify>
  <done>
    PERF-01/02/03 verified and documented in 09-01-VERIFICATION.md
  </done>
</task>

</tasks>

<verification>
- [ ] `make backend` starts successfully with query logging code present
- [ ] `ENABLE_QUERY_LOGGING=1 make backend` logs SQL queries with timing
- [ ] 09-01-VERIFICATION.md exists with test results for PERF-01, PERF-02, PERF-03
- [ ] All frontend tests pass: `make test-frontend`
- [ ] All backend tests pass: `make test-backend`
- [ ] Build succeeds: `make build-frontend`
</verification>

<success_criteria>
1. Query logging middleware added and functional
2. Parallel widget fetching verified in browser DevTools
3. SWR cache behavior verified (navigation reuse, dashboard isolation)
4. No N+1 query patterns found in report endpoints (or documented with fix plan)
5. PERF-01, PERF-02, PERF-03 requirements satisfied
</success_criteria>

<output>
After completion, create `.planning/phases/09-performance-frontend-tests/09-01-SUMMARY.md`
</output>
